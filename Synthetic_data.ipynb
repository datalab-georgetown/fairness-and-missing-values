{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file shows steps to construct synthetic data using the method shown in the paper. <br>\n",
    "We first import packages and set a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"AIF360/\")\n",
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "from aif360.datasets import StandardDataset\n",
    "from fairness_metrics.tot_metrics import TPR, TNR\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define label column. In this example, I have 10000 0's and 10000 1's for the label column. 0 is the negative outcome and 1 is the positive outcome. <br>\n",
    "We also need to define the sensitive attribute value and the correlation between sensitive attribute and the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [0] * 10000\n",
    "Y.extend([1] * 10000)\n",
    "# S here is the sensitive attribute where 0 is the unprivileged group and 1 is the privileged group\n",
    "S = []\n",
    "for i in Y:\n",
    "    if i == 0:\n",
    "        S.append(bernoulli.rvs(0.35))\n",
    "    else:\n",
    "        S.append(bernoulli.rvs(0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is to define non-sensitive features for prediction. In non-sensitive features, we need to determine the correlation between the non-sensitive feature and outcome, sensitive attibute and other non-sensitive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['y'] = Y\n",
    "df['sens'] = S\n",
    "df['tmp'] = 1\n",
    "df.groupby(['y', 'sens']).count()\n",
    "tmp = []\n",
    "for i, j in zip(df['y'], df['sens']):\n",
    "    if i == 0 and j == 0:\n",
    "        tmp.append(np.random.poisson(lam=6))\n",
    "    if i == 1 and j == 0:\n",
    "        tmp.append(np.random.poisson(lam=3))\n",
    "    if i == 0 and j == 1:\n",
    "        tmp.append(np.random.poisson(lam=4))\n",
    "    if i == 1 and j == 1:\n",
    "        tmp.append(np.random.poisson(lam=2))\n",
    "df['edu_orig'] = tmp\n",
    "tmp = df['edu_orig'].sort_values().to_list()\n",
    "\n",
    "# create 4 equal-width bins to bin continuous data into categorical\n",
    "def cat_edu(x):\n",
    "    if x <= tmp[int(len(tmp) / 4)]:\n",
    "        return 'edu_cat1'\n",
    "    elif x >= tmp[int(3 * len(tmp) / 4)]:\n",
    "        return 'edu_cat4'\n",
    "    elif x >= tmp[int(2 * len(tmp) / 4)]:\n",
    "        return 'edu_cat3'\n",
    "    else:\n",
    "        return 'edu_cat2'\n",
    "\n",
    "df['edu'] = df['edu_orig'].apply(lambda x: cat_edu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above defines the first non-sensitive feature, education and how to convert the feature into categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "tmp_list = [(i * 2 - 1) * 0.1 + (j * 2 - 1) * 0.4 + np.log(z + 1) for i, j,\n",
    "            z in zip(df['sens'].tolist(), df['y'].tolist(), df['edu_orig'].tolist())]\n",
    "for i in tmp_list:\n",
    "    temp.append(\n",
    "        np.random.normal(\n",
    "            loc=i,\n",
    "            scale=1.5) +\n",
    "        np.random.exponential(1) -\n",
    "        1)\n",
    "df['occuption_orig'] = temp\n",
    "tmp = temp\n",
    "\n",
    "\n",
    "def cat_occ(x):\n",
    "    if x <= tmp[int(len(tmp) / 4)]:\n",
    "        return 'occ_cat1'\n",
    "    elif x >= tmp[int(3 * len(tmp) / 4)]:\n",
    "        return 'occ_cat4'\n",
    "    elif x >= tmp[int(2 * len(tmp) / 4)]:\n",
    "        return 'occ_cat3'\n",
    "    else:\n",
    "        return 'occ_cat2'\n",
    "\n",
    "\n",
    "df['occuption'] = df['occuption_orig'].apply(lambda x: cat_occ(x))\n",
    "\n",
    "\n",
    "temp = []\n",
    "tmp_list = [(i * 2 - 1) * 0.05 + (j * 2 -1)*0.05 +np.log(z +1) /2 +\n",
    "            np.log(np.abs(k)+1)/5 for i,j,z,k in zip(df['sens'].tolist(),\n",
    "                                                     df['y'].tolist(),\n",
    "                                                     df['edu_orig'].tolist(),\n",
    "                                                     df['occuption_orig'].tolist())]\n",
    "for i in tmp_list:\n",
    "    temp.append(np.random.normal(loc=i,scale=1.5) + np.random.exponential(1)-1)\n",
    "df['age_orig'] = temp\n",
    "tmp = temp\n",
    "def cat_age(x):\n",
    "    if x <= tmp[int(len(tmp) / 4)]:\n",
    "        return 'age_cat1'\n",
    "    elif x >= tmp[int(3 * len(tmp) / 4)]:\n",
    "        return 'age_cat4'\n",
    "    elif x >= tmp[int(2 * len(tmp) / 4)]:\n",
    "        return 'age_cat3'\n",
    "    else:\n",
    "        return 'age_cat2'\n",
    "\n",
    "\n",
    "df['age'] = df['age_orig'].apply(lambda x: cat_age(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the part above, we define the other two non-sensitive features. Now, we have finished the synthetic data construction. <br>\n",
    "Next, we will use the synthetic data to do our missing value experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first define the distort score metrics to use the categorical fix\n",
    "def custom_distort(vold, vnew):\n",
    "    distort = {}\n",
    "    distort['edu'] = pd.DataFrame(\n",
    "        {'edu_cat1': [0., 1., 2., 3., 100.],\n",
    "         'edu_cat2': [1., 0., 1., 2., 100.],\n",
    "         'edu_cat3': [2., 1., 0., 1., 100.],\n",
    "         'edu_cat4': [3., 2., 1., 0., 100.],\n",
    "         'missing': [0., 0., 0., 0., 1.]},\n",
    "        index=['edu_cat1', 'edu_cat2', 'edu_cat3', 'edu_cat4', 'missing'])\n",
    "    distort['occuption'] = pd.DataFrame(\n",
    "        {'occ_cat1': [0., 1., 2., 3.],\n",
    "         'occ_cat2': [1., 0., 1., 2.],\n",
    "         'occ_cat3': [2., 1., 0., 1.],\n",
    "         'occ_cat4': [3., 2., 1., 0.]},\n",
    "        index=['occ_cat1', 'occ_cat2', 'occ_cat3', 'occ_cat4'])\n",
    "    distort['age'] = pd.DataFrame(\n",
    "        {'age_cat1': [0., 1., 2., 3.],\n",
    "         'age_cat2': [1., 0., 1., 2.],\n",
    "         'age_cat3': [2., 1., 0., 1.],\n",
    "         'age_cat4': [3., 2., 1., 0.]},\n",
    "        index=['age_cat1', 'age_cat2', 'age_cat3', 'age_cat4'])\n",
    "    distort['sens'] = pd.DataFrame(\n",
    "        {0.0: [0., 2.],\n",
    "         1.0: [2., 0.]},\n",
    "        index=[0.0, 1.0])\n",
    "    distort['y'] = pd.DataFrame(\n",
    "        {0.0: [0., 2.],\n",
    "         1.0: [2., 0.]},\n",
    "        index=[0.0, 1.0])\n",
    "\n",
    "    total_cost = 0.0\n",
    "    for k in vold:\n",
    "        if k in vnew:\n",
    "            total_cost += distort[k].loc[vnew[k], vold[k]]\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "class CustomDataset(StandardDataset):\n",
    "    \"\"\"Adult Census Income Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/adult/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_name='y',\n",
    "                 favorable_classes=['1'],\n",
    "                 protected_attribute_names=['x_control'],\n",
    "                 privileged_classes=['0'],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_keep=[], features_to_drop=[],\n",
    "                 na_values=[''], custom_preprocessing=None,\n",
    "                 df=None,\n",
    "                 metadata=None):\n",
    "\n",
    "        super().__init__(\n",
    "            df=df,\n",
    "            label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop,\n",
    "            na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing,\n",
    "            metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section below is how we create missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing values\n",
      "3970\n",
      "Total number of observations\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "df['y'] = df['y'].astype(int)\n",
    "df1 = df[['y', 'edu', 'occuption', 'age', 'sens']]\n",
    "tot = []\n",
    "for index, row in df1.iterrows():\n",
    "    result = ''\n",
    "    for j in df1.columns:\n",
    "        result = result + str(row[j])\n",
    "    tot.append(result)\n",
    "df['tmp_feature'] = tot\n",
    "df['mis_prob'] = 0\n",
    "# here, the first element in the column 'tmp_feature' is the label (either 0 or 1 with 0 being negative outcome) \n",
    "# and the last element is sensitive value (either 0 or 1, with 0 being unprivileged)\n",
    "# we define the proportion of missing values in the data. Here the missing values are under MAR\n",
    "for i in df['tmp_feature'].unique():\n",
    "    if i[0] == '1' and i[-1] == '0':\n",
    "        df.loc[df['tmp_feature'] == i, 'mis_prob'] = 0.05\n",
    "    elif i[-1] == '0':\n",
    "        df.loc[df['tmp_feature'] == i, 'mis_prob'] = 0.5\n",
    "    elif i[-1] != '0' and i[0] == '1':\n",
    "        df.loc[df['tmp_feature'] == i, 'mis_prob'] = 0.05\n",
    "    else:\n",
    "        df.loc[df['tmp_feature'] == i, 'mis_prob'] = 0.03\n",
    "new_label = []\n",
    "for i, j in zip(df['mis_prob'], df['edu']):\n",
    "    if np.random.binomial(1, i, 1)[0] == 1:\n",
    "        new_label.append(-1)\n",
    "    else:\n",
    "        new_label.append(j)\n",
    "df['edu'] = new_label\n",
    "print('Total number of missing values')\n",
    "print(len(df.loc[df['edu'] == -1, :].index))\n",
    "print('Total number of observations')\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we create our training and test set for training classifier and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_edu(x):\n",
    "    if x == -1:\n",
    "        return 'missing'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "df['edu'] = df['edu'].apply(lambda x: mod_edu(x))\n",
    "\n",
    "\n",
    "df_pos = df.loc[df['y'] == 1, :]\n",
    "df_neg = df.loc[df['y'] == 0, :]\n",
    "\n",
    "df_train_pos, df_test_pos = train_test_split(\n",
    "    df_pos, test_size=1000, random_state=10)\n",
    "df_train_neg, df_test_neg = train_test_split(\n",
    "    df_neg, test_size=1000, random_state=10)\n",
    "df_test = df_test_pos.append(df_test_neg)\n",
    "\n",
    "df_train_tot = df_train_pos.append(df_train_neg)\n",
    "\n",
    "_, df_train_tot_pos = train_test_split(\n",
    "    df_train_pos, test_size=4000, random_state=10)\n",
    "_, df_train_tot_neg = train_test_split(\n",
    "    df_train_neg, test_size=4000, random_state=10)\n",
    "df_train = df_train_tot_pos.append(df_train_tot_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the categorical fix using the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Preprocessing: Objective converged to 0.161315\n"
     ]
    }
   ],
   "source": [
    "orig_cat_train = df_train[['y','age', 'sens', 'occuption', 'edu']]\n",
    "orig_cat_test = df_test[['y', 'age','sens', 'occuption', 'edu']]\n",
    "\n",
    "all_protected_attribute_maps = {\"sens\": {0.0: 0, 1.0: 1}}\n",
    "D_features = ['sens']\n",
    "dataset_orig_cat_train = CustomDataset(\n",
    "    favorable_classes=[1], protected_attribute_names=['sens'], privileged_classes=[\n",
    "        [1]], categorical_features=[\n",
    "            'occuption', 'edu','age'], features_to_keep=[\n",
    "                'occuption', 'edu', 'y', 'sens','age'], df=orig_cat_train, metadata={\n",
    "                    'label_maps': [\n",
    "                        {\n",
    "                            1.0: 1, 0.0: 0}], 'protected_attribute_maps': [\n",
    "                                all_protected_attribute_maps[x] for x in D_features]})\n",
    "\n",
    "dataset_orig_cat_test = CustomDataset(\n",
    "    favorable_classes=[1], protected_attribute_names=['sens'], privileged_classes=[\n",
    "        [1]], categorical_features=[\n",
    "            'occuption', 'edu','age'], features_to_keep=[\n",
    "                'occuption', 'edu', 'y', 'sens','age'], df=orig_cat_test, metadata={\n",
    "                    'label_maps': [\n",
    "                        {\n",
    "                            1.0: 1, 0.0: 0}], 'protected_attribute_maps': [\n",
    "                                all_protected_attribute_maps[x] for x in D_features]})\n",
    "\n",
    "\n",
    "privileged_groups = [{'sens': 1}]\n",
    "unprivileged_groups = [{'sens': 0}]\n",
    "optim_options = {\n",
    "    \"distortion_fun\": custom_distort,\n",
    "    \"epsilon\": 0.08,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.2, 0.1, 0]\n",
    "}\n",
    "\n",
    "\n",
    "OP = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups=unprivileged_groups,\n",
    "                  privileged_groups=privileged_groups)\n",
    "\n",
    "OP = OP.fit(dataset_orig_cat_train)\n",
    "\n",
    "\n",
    "dataset_transf_cat_test = OP.transform(dataset_orig_cat_test, transform_Y=True)\n",
    "dataset_transf_cat_test = dataset_orig_cat_test.align_datasets(\n",
    "    dataset_transf_cat_test)\n",
    "\n",
    "\n",
    "dataset_transf_cat_train = OP.transform(\n",
    "    dataset_orig_cat_train, transform_Y=True)\n",
    "dataset_transf_cat_train = dataset_orig_cat_train.align_datasets(\n",
    "    dataset_transf_cat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the fixed training set to train our logistic regression classifier and get fairness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After categorical fix without reweight\n",
      "Accuracy\n",
      "0.727\n",
      "p-rule\n",
      "0.6268027100208016\n",
      "FPR for unpriv\n",
      "0.2822458270106222\n",
      "FNR for unpriv\n",
      "0.32098765432098764\n",
      "FPR for unpriv\n",
      "0.4134897360703812\n",
      "FNR for priv\n",
      "0.14957983193277313\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scale_transf = StandardScaler()\n",
    "X_train = dataset_orig_cat_train.features\n",
    "y_train = dataset_orig_cat_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_orig_cat_test.features)\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_cat_train.features)\n",
    "y_train = dataset_transf_cat_train.labels.ravel()\n",
    "\n",
    "X_test = scale_transf.fit_transform(dataset_transf_cat_test.features)\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('After categorical fix without reweight')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(dataset_orig_cat_test.labels, y_pred))\n",
    "\n",
    "\n",
    "dataset_orig_vt_copy1 = dataset_orig_cat_test.copy()\n",
    "dataset_orig_vt_copy1.labels = y_pred\n",
    "\n",
    "metric_transf_train1 = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_vt_copy1,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups)\n",
    "print('p-rule')\n",
    "print(metric_transf_train1.disparate_impact())\n",
    "print('FPR for unpriv')\n",
    "orig_sens_att = dataset_orig_cat_test.protected_attributes.ravel()\n",
    "print(1 - TNR(dataset_orig_cat_test.labels.ravel()\n",
    "              [orig_sens_att == 0], y_pred[orig_sens_att == 0], 1))\n",
    "print(\"FNR for unpriv\")\n",
    "print(1 - TPR(dataset_orig_cat_test.labels.ravel()\n",
    "              [orig_sens_att == 0], y_pred[orig_sens_att == 0], 1))\n",
    "\n",
    "orig_sens_att = dataset_orig_cat_test.protected_attributes.ravel()\n",
    "print('FPR for unpriv')\n",
    "print(1 - TNR(dataset_orig_cat_test.labels.ravel()\n",
    "              [orig_sens_att == 1], y_pred[orig_sens_att == 1], 1))\n",
    "print(\"FNR for priv\")\n",
    "print(1 - TPR(dataset_orig_cat_test.labels.ravel()\n",
    "              [orig_sens_att == 1], y_pred[orig_sens_att == 1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply our fixing algorithm presented in the paper to re-train the logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After categorical fix with reweight\n",
      "Accuracy\n",
      "0.72\n",
      "p-rule\n",
      "0.7654879083334302\n",
      "FPR for unpriv\n",
      "0.370257966616085\n",
      "FNR for unpriv\n",
      "0.2123456790123457\n",
      "FPR for priv\n",
      "0.4134897360703812\n",
      "FNR for priv\n",
      "0.14957983193277313\n"
     ]
    }
   ],
   "source": [
    "weight_df = dataset_orig_cat_train.convert_to_dataframe()[0]\n",
    "weight_df['weight'] = 1\n",
    "weight_df['is_missing'] = 0\n",
    "weight_df['tmp'] = ''\n",
    "tmp_result = []\n",
    "for i, j in zip(weight_df['sens'], weight_df['y']):\n",
    "    tmp_result.append(str(i) + str(j))\n",
    "weight_df['tmp'] = tmp_result\n",
    "\n",
    "weight_df.loc[weight_df['edu=missing'] == 1, 'is_missing'] = 1\n",
    "\n",
    "for i in weight_df['tmp'].unique():\n",
    "    weight_df.loc[(weight_df['tmp'] == i) & (weight_df['is_missing'] == 0),\n",
    "           'weight'] = len(weight_df.loc[(weight_df['tmp'] == i),:].index) / len(weight_df.loc[(weight_df['tmp'] == i) & (weight_df['is_missing'] == 0),:].index)\n",
    "    weight_df.loc[(weight_df['tmp'] == i) & (weight_df['is_missing'] == 1),\n",
    "           'weight'] = len(weight_df.loc[(weight_df['tmp'] == i) & (weight_df['is_missing'] == 0),:].index) / len(weight_df.loc[(weight_df['tmp'] == i),:].index)\n",
    "dataset_orig_cat_train.instance_weights = np.array(weight_df['weight'])\n",
    "\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, sample_weight=dataset_orig_cat_train.instance_weights)\n",
    "y_pred = lmod.predict(X_test)\n",
    "print('After categorical fix with reweight')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(dataset_orig_cat_test.labels, y_pred))\n",
    "\n",
    "dataset_orig_vt_copy1 = dataset_orig_cat_test.copy()\n",
    "dataset_orig_vt_copy1.labels = y_pred\n",
    "metric_transf_train1 = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_vt_copy1,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups)\n",
    "print('p-rule')\n",
    "print(metric_transf_train1.disparate_impact())\n",
    "print('FPR for unpriv')\n",
    "orig_sens_att = dataset_orig_cat_test.protected_attributes.ravel()\n",
    "print(1 - TNR(dataset_orig_cat_test.labels.ravel()[orig_sens_att == 0],\n",
    "              y_pred[orig_sens_att == 0], 1))\n",
    "print(\"FNR for unpriv\")\n",
    "print(1 - TPR(dataset_orig_cat_test.labels.ravel()[orig_sens_att == 0],\n",
    "              y_pred[orig_sens_att == 0], 1))\n",
    "\n",
    "orig_sens_att = dataset_orig_cat_test.protected_attributes.ravel()\n",
    "print('FPR for priv')\n",
    "print(1 - TNR(dataset_orig_cat_test.labels.ravel()[orig_sens_att == 1],\n",
    "              y_pred[orig_sens_att == 1], 1))\n",
    "print(\"FNR for priv\")\n",
    "print(1 - TPR(dataset_orig_cat_test.labels.ravel()[orig_sens_att == 1],\n",
    "              y_pred[orig_sens_att == 1], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, fairness scores improve a lot without much loss in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
